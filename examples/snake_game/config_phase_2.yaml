# General settings
max_iterations: 1000 # Maximum number of evolution iterations
checkpoint_interval: 20 # Save checkpoints every N iterations
log_level: "INFO" # Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
log_dir: null # Custom directory for logs (default: output_dir/logs)
random_seed: null # Random seed for reproducibility (null = random)

# Evolution settings
diff_based_evolution: false # Use diff-based evolution (true) or full rewrites (false)
allow_full_rewrites: true # Allow occasional full rewrites even in diff-based mode
max_code_length: 20000 # Maximum allowed code length in characters

# LLM configuration
llm:
  # Models for evolution
  models:
    # List of available models with their weights
    - name: "gemini-2.0-flash-lite"
      weight: 0.40
    - name: "gemini-2.0-flash"
      weight: 0.30
    - name: "gemini-2.5-flash-preview-05-20"
      weight: 0.30

  evaluator_models:
    - name: "gemini-2.0-flash-lite"
      weight: 0.40
    - name: "gemini-2.0-flash"
      weight: 0.30
    - name: "gemini-2.5-flash-preview-05-20"
      weight: 0.30

  # API configuration
  api_base: "https://generativelanguage.googleapis.com/v1beta/openai/" # Base URL for API (change for non-OpenAI models)
  api_key: null # API key (defaults to OPENAI_API_KEY env variable)

  # Generation parameters
  temperature: 0.7 # Temperature for generation (higher = more creative)
  top_p: 0.95 # Top-p sampling parameter
  max_tokens: 4096 # Maximum tokens to generate

  # Request parameters
  timeout: 60 # Timeout for API requests in seconds
  retries: 3 # Number of retries for failed requests
  retry_delay: 5 # Delay between retries in seconds

# Prompt configuration
prompt:
  template_dir: null # Custom directory for prompt templates
  system_message: |
    You are an expert AI architect, tasked with designing a next-generation strategy for a Snake game AI. The current approach, based on simple, reactive rules, has reached its performance ceiling. To achieve a significant breakthrough, we must re-frame the problem.

    Your mission is to evolve the `decide_next_move` function by treating the game not just as a race to the apple, but as a dynamic **pathfinding and survival problem** in a constrained space.

    Instead of direct, hard-coded rules, your implementation should be based on **evaluating the strategic value of future states**. The key insight is that short-term gains (like moving towards the apple) are worthless if they lead to long-term demise.

    Consider these core strategic concepts:

    1.  **Fundamental Principle: Maximize Future Options.** The primary goal is not just to survive the next move, but to ensure the snake always has the maximum possible space to maneuver in the future. A move is only good if the resulting position is "open" and not a dead end.
    2.  **Rethink the Apple's Value.** An apple is not always a reward. It can be a trap. Before pursuing an apple, the AI must ask: "If I eat this apple, will I trap myself?" A critical heuristic is to simulate eating the apple and then checking if a safe path to the new tail position still exists. If not, the apple must be ignored.
    3.  **The Board as a Graph.** Treat the grid as a graph where empty squares are nodes. The problem then becomes finding the optimal path through this constantly changing graph. Your code should reflect this understanding. Think about how you would explore this graph to assess the quality of different paths.

    Focus on breaking through the current plateau by implementing a **fundamentally different, more abstract decision-making process**. Instead of a series of `if/else` checks, the new logic should calculate a "desirability score" for each possible move, based on a weighted combination of factors like resulting available space, safety, and path-to-apple feasibility.

  evaluator_system_message: |
    You are an expert code reviewer specializing in game AI. Your task is to analyze a Python function that decides a snake's next move.

    Evaluate the submitted strategy based on the following criteria on a scale of 1 to 10, where 1 is poor and 10 is excellent.
    1.  **Correctness and Safety (Weight: 50%)**: Does the code reliably prevent immediate collisions with walls, obstacles, and its own body? Is it robust against edge cases?
    2.  **Strategic Foresight (Weight: 40%)**: Does the logic show any signs of "thinking ahead"? Does it avoid moving into spaces where it could easily get trapped later, even if it's a short-term optimal move? A simple "move towards apple" logic is a low score. Logic that seems to map out safe areas or avoid dead ends is a high score.
    3.  **Readability and Simplicity (Weight: 10%)**: Is the code clean, well-commented, and easy to understand?

    You MUST respond ONLY with a JSON object containing your reasoning and a final weighted score. Example:
    {
      "reasoning": "The code correctly avoids immediate collisions but lacks any strategic foresight, leading it into simple traps. It's a basic reactive AI.",
      "final_score": 4.5
    }

  # Number of examples to include in the prompt
  num_top_programs: 4 # Number of top-performing programs to include
  num_diverse_programs: 2 # Number of diverse programs to include

  # Template stochasticity
  use_template_stochasticity: true # Use random variations in templates for diversity

  # Artifacts Channel
  include_artifacts: true
  max_artifact_bytes: 4096 # 4KB limit in prompts
  artifact_security_filter: true

database:
  # General settings
  db_path: null # Path to persist database (null = in-memory only)
  in_memory: true # Keep database in memory for faster access

  # Evolutionary parameters
  population_size: 1000 # Maximum number of programs to keep in memory
  archive_size: 100 # Size of elite archive
  num_islands: 6 # Number of islands for island model (separate populations)

  # Island-based evolution parameters
  # Islands provide diversity by maintaining separate populations that evolve independently.
  # Migration periodically shares the best solutions between adjacent islands.
  migration_interval: 50 # Migrate between islands every N generations
  migration_rate: 0.1 # Fraction of top programs to migrate (0.1 = 10%)

  # Selection parameters
  elite_selection_ratio: 0.2 # Ratio of elite programs to select
  exploration_ratio: 0.2 # Ratio of exploration vs exploitation
  exploitation_ratio: 0.6 # Ratio of exploitation vs random selection
  # Note: diversity_metric is fixed to "edit_distance" (feature_based not implemented)

  # Feature map dimensions for MAP-Elites
  feature_dimensions: # Dimensions for MAP-Elites feature map
    - "score" # Performance score
    - "complexity" # Code complexity (length)
  feature_bins: 10 # Number of bins per dimension

# Evaluator configuration
evaluator:
  # General settings
  timeout: 300 # Maximum evaluation time in seconds
  max_retries: 3 # Maximum number of retries for evaluation

  # Note: resource limits (memory_limit_mb, cpu_limit) are not yet implemented

  # Evaluation strategies
  cascade_evaluation: true # Use cascade evaluation to filter bad solutions early
  cascade_thresholds: # Thresholds for advancing to next evaluation stage
    - 10 # First stage threshold
    - 20 # Second stage threshold
    - 30 # Third stage threshold

  # Parallel evaluation
  parallel_evaluations: 4 # Number of parallel evaluations
  # Note: distributed evaluation is not yet implemented

  # LLM-based feedback (experimental)
  use_llm_feedback: false # Use LLM to evaluate code quality
  llm_feedback_weight: 0.1 # Weight for LLM feedback in final score
  enable_artifacts: true
